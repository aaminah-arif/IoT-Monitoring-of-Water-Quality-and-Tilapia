# ğŸŒŠ IoT Monitoring Dataset of Water Quality and Tilapia Health in Aquaculture Ponds (MonterÃ­a, Colombia - 2024)

This project explores the application of logistic regression to analyze a real-world aquaculture dataset collected using IoT sensors. The dataset includes water quality parameters and tilapia health indicators gathered over six months in MonterÃ­a, Colombia.

The goal is to build a predictive model for fish health status ("Stable" vs. "At Risk") using environmental and operational variables.

## ğŸ“‚ Dataset Description

**File:** `Data Model IoTMLCQ 2024.xlsx` â€“ Contains hourly sensor and health data from January to June 2024.

### ğŸ“ Features (Inputs)
- `Temperature (Â°C)`
- `Dissolved Oxygen (mg/L)`
- `pH`
- `Turbidity (NTU)`
- `Oxygenation Automatic` (Yes/No â†’ Encoded as 1/0)
- `Oxygenation Interventions` (Yes/No â†’ Encoded as 1/0)
- `Corrective Interventions`
- `Thermal Risk Index` (High/Normal â†’ Encoded)
- `Low Oxygen Alert` (Critical/Safe â†’ Encoded)

### ğŸ¯ Target (Output)
- `Health Status`: Categorical feature representing fish health condition:
  - `Stable` â†’ 0
  - `At Risk` â†’ 1

## ğŸ¯ Objective

We aim to:

1. **Predict the fish health status** based on water quality and operational variables.
2. Train a logistic regression classifier using:
   - Python libraries (`scikit-learn`)
   - Gradient Descent from scratch
   - Newton-Raphson Algorithm
3. Compare performance and optimal parameters from each method.

## ğŸ“ Logistic Regression Model

The logistic regression hypothesis is defined as:

$$
h_{\theta}(X) = \sigma(X\theta) = \frac{1}{1 + e^{-X\theta}}
$$

Where:
- \( X \) is the feature matrix (including a bias term).
- \( \theta \) is the parameter vector.
- \( h_{\theta}(X) \) is the probability that the fish is "At Risk".

## ğŸ§¹ Data Preparation

### 1. Cleaning:
- Missing data interpolated using linear methods
- Categorical features encoded (One-Hot Encoding)

### 2. Feature Scaling:
- Features normalized using `StandardScaler` (mean = 0, std = 1)

### 3. Train-Test Split:
- 80% for training, 20% for testing

## ğŸ§ª Model Training

### ğŸ”¹ 1. Using Python Libraries

- **Library:** `scikit-learn`
- **Model:** `LogisticRegression(solver='liblinear')`
- **Optimal Parameters:** Displayed after fitting
- **Evaluation Metrics:** Accuracy, Precision, Recall, F1-score, Confusion Matrix

### ğŸ”¹ 2. Using Gradient Descent

- Implemented from scratch.
- Learning Rate (Î±) tuned via grid search.
- Parameters updated using:

$$
\theta := \theta - \alpha \nabla J(\theta)
$$

- **Comparison:** Training accuracy vs. library implementation.

### ğŸ”¹ 3. Using Newton-Raphson Algorithm

The Newton-Raphson method implements the following update rule:

$$
\theta := \theta - H^{-1} \nabla J(\theta)
$$

Where:
- \( H \) is the Hessian matrix of the cost function.

This method usually converges faster than Gradient Descent (GD) for convex problems like logistic regression.

**Comparison:** Iteration count and final accuracy vs. GD and library-based method.

## ğŸ“ Usage Notes

- This dataset is ideal for research in **aquaculture monitoring**, **fish health modeling**, and **IoT-driven environmental analytics**.
- Sensor accuracy is ensured via routine calibration.
- Health risks were defined based on domain-specific thresholds (e.g., DO < 5 mg/L â†’ "Critical").
